{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Project Description**\n",
        "\n",
        "\n",
        "This notebook presents a systematic comparative benchmark of three popular deep learning architectures—Bi-directional Long Short-Term Memory (Bi-LSTM), Gated Recurrent Unit (GRU), and 1D Convolutional Neural Network (Conv1D)—for the task of text classification (specifically, sentiment analysis).\n",
        "\n",
        "**Objective**\n",
        "\n",
        "The primary goal is to evaluate the trade-offs between sequential models (Bi-LSTM, GRU) and pattern-based models (Conv1D) in terms of prediction accuracy, computational cost (training time), and model complexity (trainable parameters).\n",
        "\n",
        "**Methodology**\n",
        "\n",
        "Data Preprocessing:\n",
        "\n",
        "The text data is tokenized using Keras's Tokenizer, and sequences are padded to a uniform length (MAX_LEN).\n",
        "\n",
        "Labels are converted using LabelBinarizer.\n",
        "\n",
        "**Model Definition**:\n",
        "\n",
        "A factory function (create_model) defines each of the three architectures with an initial Embedding layer, followed by the respective core layer (Bi-LSTM, GRU, or Conv1D + GlobalMaxPooling), and standard dense output layers.\n",
        "\n",
        "**Benchmarking**:\n",
        "\n",
        "The run_benchmark function trains each model, evaluates its performance on a held-out test set, and measures the wall-clock training time.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D_OHkO58mySY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Embedding, Bidirectional, LSTM, GRU, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xZK-mrHxewX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#DRIVE_FILE_PATH =\n",
        "\n",
        "\n",
        "if os.path.exists(DRIVE_FILE_PATH):\n",
        "\n",
        "    df = pd.read_csv(DRIVE_FILE_PATH, encoding='latin-1')\n",
        "    print(\"Data loaded successfully.\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"ERROR: {DRIVE_FILE_PATH} not found. \"\n",
        "                            \"Please check the file path and ensure the file exists in your Google Drive.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 100\n",
        "EMBEDDING_DIM = 64\n",
        "\n",
        "NUM_CLASSES = len(df['Sentiment'].unique()) if 'Sentiment' in df.columns else len(df.iloc[:, 1].unique())\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "df.columns = ['text', 'label']\n",
        "df.dropna(subset=['text', 'label'], inplace=True)\n",
        "\n",
        "\n",
        "X = df['text'].values\n",
        "y = df['label'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_train_ohe = lb.fit_transform(y_train)\n",
        "y_test_ohe = lb.transform(y_test)\n",
        "CLASS_NAMES = lb.classes_.astype(str)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "print(f\"Data ready. Sequences padded to length {MAX_LEN}.\")\n",
        "print(f\"Train samples: {X_train_padded.shape[0]}, Test samples: {X_test_padded.shape[0]}\")\n",
        "\n",
        "\n",
        "def create_model(model_type):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=MAX_LEN))\n",
        "\n",
        "    if model_type == 'Bi-LSTM':\n",
        "\n",
        "        model.add(Bidirectional(LSTM(64)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    elif model_type == 'GRU':\n",
        "\n",
        "        model.add(GRU(64))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    elif model_type == 'Conv1D':\n",
        "\n",
        "        model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "        model.add(GlobalMaxPooling1D())\n",
        "\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_benchmark(model_type):\n",
        "    print(f\"\\n---  BUILDING {model_type} Model ---\")\n",
        "    model = create_model(model_type)\n",
        "\n",
        "\n",
        "    print(f\"---  TRAINING {model_type} ---\")\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train_padded, y_train_ohe,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_split=0.1,\n",
        "        verbose=0\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test_padded, y_test_ohe, verbose=0)\n",
        "\n",
        "\n",
        "    y_pred_ohe = model.predict(X_test_padded, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_ohe, axis=1)\n",
        "    y_test_labels = y_test_ohe.argmax(axis=1)\n",
        "\n",
        "    report = classification_report(y_test_labels, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
        "\n",
        "    metrics = {\n",
        "        'Test Accuracy': accuracy,\n",
        "        'Training Time (s)': training_time,\n",
        "        'F1-Score (Macro Avg)': report['macro avg']['f1-score'],\n",
        "        'Precision (Macro Avg)': report['macro avg']['precision'],\n",
        "        'Recall (Macro Avg)': report['macro avg']['recall'],\n",
        "        'Trainable Parameters': model.count_params()\n",
        "    }\n",
        "\n",
        "    print(f\" {model_type} complete. Accuracy: {accuracy:.4f}, Time: {training_time:.2f}s\")\n",
        "    return metrics, model\n",
        "\n",
        "\n",
        "models_to_test = ['Bi-LSTM', 'GRU', 'Conv1D']\n",
        "benchmark_results = {}\n",
        "trained_models = {}\n",
        "\n",
        "for model_type in models_to_test:\n",
        "    metrics, model = run_benchmark(model_type)\n",
        "    benchmark_results[model_type] = metrics\n",
        "    trained_models[model_type] = model\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"              DEEP LEARNING MODEL BENCHMARK RESULTS \")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results_df = pd.DataFrame(benchmark_results).T\n",
        "\n",
        "\n",
        "results_df['Test Accuracy'] = (results_df['Test Accuracy'] * 100).map('{:.2f}%'.format)\n",
        "results_df['F1-Score (Macro Avg)'] = results_df['F1-Score (Macro Avg)'].map('{:.3f}'.format)\n",
        "results_df['Training Time (s)'] = results_df['Training Time (s)'].map('{:.2f}s'.format)\n",
        "results_df['Trainable Parameters'] = results_df['Trainable Parameters'].map('{:,}'.format)\n",
        "\n",
        "\n",
        "best_model = max(benchmark_results, key=lambda k: benchmark_results[k]['Test Accuracy'])\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\" **BEST PERFORMER (by Test Accuracy): {best_model}** \")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "print(\"\\n### ARCHITECTURAL ANALYSIS:\")\n",
        "print(\"* **Recurrent Models (Bi-LSTM, GRU):** These models excel at sequential data, capturing context by remembering information across the sequence (the 'memory' effect).\")\n",
        "print(\"  * **Bi-LSTM** is the most complex, offering high accuracy by processing text both forward and backward, but it is typically the slowest to train.\")\n",
        "print(\"  * **GRU** is a simplified, two-gate version of LSTM. It often offers a near-LSTM performance level while being computationally more efficient and faster to train.\")\n",
        "print(\"* **Convolutional Model (Conv1D):** This model operates like a pattern detector, scanning for local patterns (n-grams). It is exceptionally fast because convolutions are highly parallelizable (run simultaneously across the sequence).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkZjdpMkepPb",
        "outputId": "f90b6d4c-5189-4501-9e74-ec786c99d085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Data ready. Sequences padded to length 100.\n",
            "Train samples: 192742, Test samples: 48186\n",
            "\n",
            "---  BUILDING Bi-LSTM Model ---\n",
            "---  TRAINING Bi-LSTM ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bi-LSTM complete. Accuracy: 0.8418, Time: 6270.96s\n",
            "\n",
            "---  BUILDING GRU Model ---\n",
            "---  TRAINING GRU ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GRU complete. Accuracy: 0.4278, Time: 4355.75s\n",
            "\n",
            "---  BUILDING Conv1D Model ---\n",
            "---  TRAINING Conv1D ---\n",
            " Conv1D complete. Accuracy: 0.8405, Time: 1663.47s\n",
            "\n",
            "======================================================================\n",
            "              DEEP LEARNING MODEL BENCHMARK RESULTS \n",
            "======================================================================\n",
            "        Test Accuracy Training Time (s) F1-Score (Macro Avg)  \\\n",
            "Bi-LSTM        84.18%          6270.96s                0.834   \n",
            "GRU            42.78%          4355.75s                0.200   \n",
            "Conv1D         84.05%          1663.47s                0.832   \n",
            "\n",
            "         Precision (Macro Avg)  Recall (Macro Avg) Trainable Parameters  \n",
            "Bi-LSTM               0.833726            0.833335            710,275.0  \n",
            "GRU                   0.409255            0.333478            667,139.0  \n",
            "Conv1D                0.831810            0.832951            685,315.0  \n",
            "\n",
            "======================================================================\n",
            " **BEST PERFORMER (by Test Accuracy): Bi-LSTM** \n",
            "======================================================================\n",
            "\n",
            "### ARCHITECTURAL ANALYSIS:\n",
            "* **Recurrent Models (Bi-LSTM, GRU):** These models excel at sequential data, capturing context by remembering information across the sequence (the 'memory' effect).\n",
            "  * **Bi-LSTM** is the most complex, offering high accuracy by processing text both forward and backward, but it is typically the slowest to train.\n",
            "  * **GRU** is a simplified, two-gate version of LSTM. It often offers a near-LSTM performance level while being computationally more efficient and faster to train.\n",
            "* **Convolutional Model (Conv1D):** This model operates like a pattern detector, scanning for local patterns (n-grams). It is exceptionally fast because convolutions are highly parallelizable (run simultaneously across the sequence).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Key Findings**\n",
        "\n",
        "The results provide clear insight into the performance characteristics of each model:\n",
        "\n",
        "**Bi-LSTM**:\n",
        "\n",
        "It offers the highest accuracy due to its ability to capture long-range dependencies in both forward and backward directions, but it is the most time-intensive to train.\n",
        "\n"
      ],
      "metadata": {
        "id": "mjeZ4waDn6U5"
      }
    }
  ]
}